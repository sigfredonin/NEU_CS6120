Python 3.6.0 |Anaconda 4.3.1 (32-bit)| (default, Dec 23 2016, 12:06:52) [MSC v.1900 32 bit (Intel)] on win32
Type "copyright", "credits" or "license()" for more information.
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 28, 2018 10:07:56 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 12:07:07 AM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
Traceback (most recent call last):
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 344, in <module>
    print(fnx_unk[:30])
TypeError: unhashable type: 'slice'
>>> print(list(fnx_unk)[:10])
['[', 'Austen', '1816', ']', 'VOLUME', 'unite', 'twenty-one', 'vex', 'youngest', 'indulgent']
>>> print(list(fnx_unk.items())[:10])
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2)]
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 12:09:48 AM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:06:38 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:08:48 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
Traceback (most recent call last):
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 341, in <module>
    print(fnx_unk.items()[:30])
TypeError: 'dict_items' object is not subscriptable
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:10:10 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:19:06 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Traceback (most recent call last):
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 360, in <module>
    model.preprocess_file_to_tokens(pathGutenberg, fnx)
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 107, in preprocess_file_to_tokens
    fnx_words = self.words_from_sents(self, fnx_sents)
TypeError: words_from_sents() takes 2 positional arguments but 3 were given
>>> fnx_sents[:10]
[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']'], ['VOLUME', 'I'], ['CHAPTER', 'I'], ['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.'], ['She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', "'", 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.'], ['Her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', ';', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', ',', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.'], ['Sixteen', 'years', 'had', 'Miss', 'Taylor', 'been', 'in', 'Mr', '.', 'Woodhouse', "'", 's', 'family', ',', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', ',', 'very', 'fond', 'of', 'both', 'daughters', ',', 'but', 'particularly', 'of', 'Emma', '.'], ['Between', '_them_', 'it', 'was', 'more', 'the', 'intimacy', 'of', 'sisters', '.'], ['Even', 'before', 'Miss', 'Taylor', 'had', 'ceased', 'to', 'hold', 'the', 'nominal', 'office', 'of', 'governess', ',', 'the', 'mildness', 'of', 'her', 'temper', 'had', 'hardly', 'allowed', 'her', 'to', 'impose', 'any', 'restraint', ';', 'and', 'the', 'shadow', 'of', 'authority', 'being', 'now', 'long', 'passed', 'away', ',', 'they', 'had', 'been', 'living', 'together', 'as', 'friend', 'and', 'friend', 'very', 'mutually', 'attached', ',', 'and', 'Emma', 'doing', 'just', 'what', 'she', 'liked', ';', 'highly', 'esteeming', 'Miss', 'Taylor', "'", 's', 'judgment', ',', 'but', 'directed', 'chiefly', 'by', 'her', 'own', '.'], ['The', 'real', 'evils', ',', 'indeed', ',', 'of', 'Emma', "'", 's', 'situation', 'were', 'the', 'power', 'of', 'having', 'rather', 'too', 'much', 'her', 'own', 'way', ',', 'and', 'a', 'disposition', 'to', 'think', 'a', 'little', 'too', 'well', 'of', 'herself', ';', 'these', 'were', 'the', 'disadvantages', 'which', 'threatened', 'alloy', 'to', 'her', 'many', 'enjoyments', '.']]
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:28:50 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Count sentences: 7493
First 5 sentences --
['[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.', "She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period.", 'Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection.', "Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma.", 'Between _them_ it was more the intimacy of sisters.', "Even before Miss Taylor had ceased to hold the nominal office of governess, the mildness of her temper had hardly allowed her to impose any restraint; and the shadow of authority being now long passed away, they had been living together as friend and friend very mutually attached, and Emma doing just what she liked; highly esteeming Miss Taylor's judgment, but directed chiefly by her own.", "The real evils, indeed, of Emma's situation were the power of having rather too much her own way, and a disposition to think a little too well of herself; these were the disadvantages which threatened alloy to her many enjoyments.", 'The danger, however, was at present so unperceived, that they did not by any means rank as misfortunes with her.', 'Sorrow came--a gentle sorrow--but not at all in the shape of any disagreeable consciousness.--Miss Taylor married.', "It was Miss Taylor's loss which first brought grief.", 'It was on the wedding-day of this beloved friend that Emma first sat in mournful thought of any continuance.', 'The wedding over, and the bride-people gone, her father and herself were left to dine together, with no prospect of a third to cheer a long evening.', 'Her father composed himself to sleep after dinner, as usual, and she had then only to sit and think of what she had lost.', 'The event had every promise of happiness for her friend.', "Mr. Weston was a man of unexceptionable character, easy fortune, suitable age, and pleasant manners; and there was some satisfaction in considering with what self-denying, generous friendship she had always wished and promoted the match; but it was a black morning's work for her.", 'The want of Miss Taylor would be felt every hour of every day.', 'She recalled her past kindness--the kindness, the affection of sixteen years--how she had taught and how she had played with her from five years old--how she had devoted all her powers to attach and amuse her in health--and how nursed her through the various illnesses of childhood.', "A large debt of gratitude was owing here; but the intercourse of the last seven years, the equal footing and perfect unreserve which had soon followed Isabella's marriage, on their being left to each other, was yet a dearer, tenderer recollection.", 'She had been a friend and companion such as few possessed: intelligent, well-informed, useful, gentle, knowing all the ways of the family, interested in all its concerns, and peculiarly interested in herself, in every pleasure, every scheme of hers--one to whom she could speak every thought as it arose, and who had such an affection for her as could never find fault.', 'How was she to bear the change?--It was true that her friend was going only half a mile from them; but Emma was aware that great must be the difference between a Mrs. Weston, only half a mile from them, and a Miss Taylor in the house; and with all her advantages, natural and domestic, she was now in great danger of suffering from intellectual solitude.', 'She dearly loved her father, but he was no companion for her.', 'He could not meet her in conversation, rational or playful.', 'The evil of the actual disparity in their ages (and Mr. Woodhouse had not married early) was much increased by his constitution and habits; for having been a valetudinarian all his life, without activity of mind or body, he was a much older man in ways than in years; and though everywhere beloved for the friendliness of his heart and his amiable temper, his talents could not have recommended him at any time.', 'Her sister, though comparatively but little removed by matrimony, being settled in London, only sixteen miles off, was much beyond her daily reach; and many a long October and November evening must be struggled through at Hartfield, before Christmas brought the next visit from Isabella and her husband, and their little children, to fill the house, and give her pleasant society again.', 'Highbury, the large and populous village, almost amounting to a town, to which Hartfield, in spite of its separate lawn, and shrubberies, and name, did really belong, afforded her no equals.', 'The Woodhouses were first in consequence there.', 'All looked up to them.', 'She had many acquaintance in the place, for her father was universally civil, but not one among them who could be accepted in lieu of Miss Taylor for even half a day.', 'It was a melancholy change; and Emma could not but sigh over it, and wish for impossible things, till her father awoke, and made it necessary to be cheerful.', 'His spirits required support.']
Count of word tokens: 206731
First 30 word tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
Count UNK tokens: 6309
First 30 UNK tokens --
Traceback (most recent call last):
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 371, in <module>
    print(fnx_0_unk[:30])
TypeError: unhashable type: 'slice'
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:30:30 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Count sentences: 7493
First 5 sentences --
['[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.', "She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period.", 'Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection.', "Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma.", 'Between _them_ it was more the intimacy of sisters.']
Count of word tokens: 206731
First 30 word tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count of prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 05:35:37 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Count sentences: 7493
First 5 sentences --
['[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.', "She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period.", 'Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection.', "Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma.", 'Between _them_ it was more the intimacy of sisters.']
Count of word tokens: 206731
First 30 word tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count of prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test add_grams() --
austen-emma.txt                   173752    173752
Count of 4-grams used more than once: 10538
Sample 30 repeated 4-grams ---
[(('some', 'of', 'the', 'best'), 2), (('the', 'best', 'blessings', 'of'), 2), (('best', 'blessings', 'of', 'existence'), 2), (('blessings', 'of', 'existence', ';'), 2), (('her', '.', '</s>', '<s>'), 110), (('.', '</s>', '<s>', 'She'), 413), (('</s>', '<s>', 'She', 'was'), 94), (('<s>', 'She', 'was', 'the'), 3), (('was', 'the', 'youngest', 'of'), 2), (('the', 'youngest', 'of', 'the'), 2), (('youngest', 'of', 'the', 'two'), 2), (('of', 'the', 'two', 'daughters'), 2), (('the', 'two', 'daughters', 'of'), 2), (('two', 'daughters', 'of', 'a'), 2), (('of', 'her', 'sister', "'s"), 2), (('period', '.', '</s>', '<s>'), 2), (('.', '</s>', '<s>', 'Her'), 76), (('for', 'her', 'to', 'have'), 3), (('affection', '.', '</s>', '<s>'), 5), (('.', '</s>', '<s>', 'Sixteen'), 2), (('in', 'Mr.', 'Woodhouse', "'s"), 2), (('Mr.', 'Woodhouse', "'s", 'family'), 2), (('of', 'Emma', '.', '</s>'), 2), (('Emma', '.', '</s>', '<s>'), 44), (('.', '</s>', '<s>', 'Even'), 8), (('long', 'passed', 'away', ','), 2), (('her', 'own', '.', '</s>'), 8), (('own', '.', '</s>', '<s>'), 15), (('.', '</s>', '<s>', 'The'), 251), ((',', 'indeed', ',', 'of'), 2)]
>>> fnx_0_4_repeats_total = sum([ count for gram, count in fnx_0_repeats ])
>>> fnx_0_4_repeats_total
43513
>>> 173752 + 43513
217265
>>> 173752 + 43513 - 10538
206727
>>> 173752 + 43513 - 10538 + 4
206731
>>> 173752 + (43513 - 10538) + 4
206731
>>> fnx_0_4_grams_total = sum([ count for gram, count in fnx_0_4_grams ])
Traceback (most recent call last):
  File "<pyshell#9>", line 1, in <module>
    fnx_0_4_grams_total = sum([ count for gram, count in fnx_0_4_grams ])
  File "<pyshell#9>", line 1, in <listcomp>
    fnx_0_4_grams_total = sum([ count for gram, count in fnx_0_4_grams ])
ValueError: too many values to unpack (expected 2)
>>> len(fnx_0_4_grams)
173752
>>> fnx_0_4_grams[:10]
Traceback (most recent call last):
  File "<pyshell#11>", line 1, in <module>
    fnx_0_4_grams[:10]
TypeError: unhashable type: 'slice'
>>> list(fnx_0_4_grams.items())[:10]
[(('<s>', '[', 'Emma', 'by'), 1), (('[', 'Emma', 'by', 'Jane'), 1), (('Emma', 'by', 'Jane', 'Austen'), 1), (('by', 'Jane', 'Austen', '1816'), 1), (('Jane', 'Austen', '1816', ']'), 1), (('Austen', '1816', ']', 'VOLUME'), 1), (('1816', ']', 'VOLUME', 'I'), 1), ((']', 'VOLUME', 'I', 'CHAPTER'), 1), (('VOLUME', 'I', 'CHAPTER', 'I'), 1), (('I', 'CHAPTER', 'I', 'Emma'), 1)]
>>> len(list(fnx_0_4_grams.items()))
173752
>>> fnx_0_4_grams_total = sum([ count for gram, count in fnx_0_4_grams.items() ])
>>> fnx_0_4_grams_total
206727
>>> list(fnx_0_4_grams.items())[-10:]
[(('fully', 'answered', 'in', 'the'), 1), (('answered', 'in', 'the', 'perfect'), 1), (('in', 'the', 'perfect', 'happiness'), 1), (('the', 'perfect', 'happiness', 'of'), 1), (('perfect', 'happiness', 'of', 'the'), 1), (('happiness', 'of', 'the', 'union'), 1), (('of', 'the', 'union', '.'), 1), (('the', 'union', '.', '</s>'), 1), (('union', '.', '</s>', '<s>'), 1), (('.', '</s>', '<s>', 'FINIS'), 1)]
>>> fnx_0_tokens[-30:]
[',', 'the', 'predictions', 'of', 'the', 'small', 'band', 'of', 'true', 'friends', 'who', 'witnessed', 'the', 'ceremony', ',', 'were', 'fully', 'answered', 'in', 'the', 'perfect', 'happiness', 'of', 'the', 'union', '.', '</s>', '<s>', 'FINIS', '</s>']
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 06:02:14 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Count sentences: 7493
First 5 sentences --
['[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.', "She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period.", 'Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection.', "Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma.", 'Between _them_ it was more the intimacy of sisters.']
Count of word tokens: 206731
First 30 word tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count of prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test add_grams() --
austen-emma.txt                   173753    173753
Count of 4-grams used more than once: 10538
Total instances of repeated 4-grams: 43513
Count of 4-gram instances in text: 206728
Sample 30 repeated 4-grams ---
[(('some', 'of', 'the', 'best'), 2), (('the', 'best', 'blessings', 'of'), 2), (('best', 'blessings', 'of', 'existence'), 2), (('blessings', 'of', 'existence', ';'), 2), (('her', '.', '</s>', '<s>'), 110), (('.', '</s>', '<s>', 'She'), 413), (('</s>', '<s>', 'She', 'was'), 94), (('<s>', 'She', 'was', 'the'), 3), (('was', 'the', 'youngest', 'of'), 2), (('the', 'youngest', 'of', 'the'), 2), (('youngest', 'of', 'the', 'two'), 2), (('of', 'the', 'two', 'daughters'), 2), (('the', 'two', 'daughters', 'of'), 2), (('two', 'daughters', 'of', 'a'), 2), (('of', 'her', 'sister', "'s"), 2), (('period', '.', '</s>', '<s>'), 2), (('.', '</s>', '<s>', 'Her'), 76), (('for', 'her', 'to', 'have'), 3), (('affection', '.', '</s>', '<s>'), 5), (('.', '</s>', '<s>', 'Sixteen'), 2), (('in', 'Mr.', 'Woodhouse', "'s"), 2), (('Mr.', 'Woodhouse', "'s", 'family'), 2), (('of', 'Emma', '.', '</s>'), 2), (('Emma', '.', '</s>', '<s>'), 44), (('.', '</s>', '<s>', 'Even'), 8), (('long', 'passed', 'away', ','), 2), (('her', 'own', '.', '</s>'), 8), (('own', '.', '</s>', '<s>'), 15), (('.', '</s>', '<s>', 'The'), 251), ((',', 'indeed', ',', 'of'), 2)]
First 30 4-grams --
Traceback (most recent call last):
  File "D:\Documents\NLP\NEU_CS6120\n_grams_lm.py", line 390, in <module>
    print(fnx_0_4_grams[:30])
TypeError: unhashable type: 'slice'
>>> 
============= RESTART: D:\Documents\NLP\NEU_CS6120\n_grams_lm.py =============
====September 29, 2018 06:04:27 PM====
-- test infrequent_to_UNK() --
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test preprocess_file_to_tokens() --
prep tokens for austen-emma.txt
Count sentences: 7493
First 5 sentences --
['[Emma by Jane Austen 1816] VOLUME I CHAPTER I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.', "She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister's marriage, been mistress of his house from a very early period.", 'Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection.', "Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma.", 'Between _them_ it was more the intimacy of sisters.']
Count of word tokens: 206731
First 30 word tokens --
['<s>', '[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
Count UNK tokens: 6309
First 30 UNK tokens --
[('[', 2), ('Austen', 1), ('1816', 1), (']', 2), ('VOLUME', 3), ('unite', 3), ('twenty-one', 1), ('vex', 1), ('youngest', 4), ('indulgent', 2), ('died', 4), ('indistinct', 1), ('caresses', 1), ('supplied', 5), ('Sixteen', 2), ('Between', 2), ('_them_', 4), ('nominal', 1), ('mildness', 1), ('impose', 1), ('restraint', 3), ('shadow', 2), ('mutually', 3), ('esteeming', 1), ('disadvantages', 1), ('threatened', 4), ('alloy', 3), ('enjoyments', 3), ('unperceived', 2), ('misfortunes', 1)]
Count of prepped tokens: 206731
First 30 prepped tokens --
['<s>', 'UNK', 'Emma', 'by', 'Jane', 'UNK', 'UNK', 'UNK', 'UNK', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',']
-- test add_grams() --
austen-emma.txt                   173753    173753
Count of 4-grams used more than once: 10538
Total instances of repeated 4-grams: 43513
Count of 4-gram instances in text: 206728
Sample 30 repeated 4-grams ---
[(('some', 'of', 'the', 'best'), 2), (('the', 'best', 'blessings', 'of'), 2), (('best', 'blessings', 'of', 'existence'), 2), (('blessings', 'of', 'existence', ';'), 2), (('her', '.', '</s>', '<s>'), 110), (('.', '</s>', '<s>', 'She'), 413), (('</s>', '<s>', 'She', 'was'), 94), (('<s>', 'She', 'was', 'the'), 3), (('was', 'the', 'youngest', 'of'), 2), (('the', 'youngest', 'of', 'the'), 2), (('youngest', 'of', 'the', 'two'), 2), (('of', 'the', 'two', 'daughters'), 2), (('the', 'two', 'daughters', 'of'), 2), (('two', 'daughters', 'of', 'a'), 2), (('of', 'her', 'sister', "'s"), 2), (('period', '.', '</s>', '<s>'), 2), (('.', '</s>', '<s>', 'Her'), 76), (('for', 'her', 'to', 'have'), 3), (('affection', '.', '</s>', '<s>'), 5), (('.', '</s>', '<s>', 'Sixteen'), 2), (('in', 'Mr.', 'Woodhouse', "'s"), 2), (('Mr.', 'Woodhouse', "'s", 'family'), 2), (('of', 'Emma', '.', '</s>'), 2), (('Emma', '.', '</s>', '<s>'), 44), (('.', '</s>', '<s>', 'Even'), 8), (('long', 'passed', 'away', ','), 2), (('her', 'own', '.', '</s>'), 8), (('own', '.', '</s>', '<s>'), 15), (('.', '</s>', '<s>', 'The'), 251), ((',', 'indeed', ',', 'of'), 2)]
First 30 4-grams --
[(('<s>', '[', 'Emma', 'by'), 1), (('[', 'Emma', 'by', 'Jane'), 1), (('Emma', 'by', 'Jane', 'Austen'), 1), (('by', 'Jane', 'Austen', '1816'), 1), (('Jane', 'Austen', '1816', ']'), 1), (('Austen', '1816', ']', 'VOLUME'), 1), (('1816', ']', 'VOLUME', 'I'), 1), ((']', 'VOLUME', 'I', 'CHAPTER'), 1), (('VOLUME', 'I', 'CHAPTER', 'I'), 1), (('I', 'CHAPTER', 'I', 'Emma'), 1), (('CHAPTER', 'I', 'Emma', 'Woodhouse'), 1), (('I', 'Emma', 'Woodhouse', ','), 1), (('Emma', 'Woodhouse', ',', 'handsome'), 1), (('Woodhouse', ',', 'handsome', ','), 1), ((',', 'handsome', ',', 'clever'), 1), (('handsome', ',', 'clever', ','), 1), ((',', 'clever', ',', 'and'), 1), (('clever', ',', 'and', 'rich'), 1), ((',', 'and', 'rich', ','), 1), (('and', 'rich', ',', 'with'), 1), (('rich', ',', 'with', 'a'), 1), ((',', 'with', 'a', 'comfortable'), 1), (('with', 'a', 'comfortable', 'home'), 1), (('a', 'comfortable', 'home', 'and'), 1), (('comfortable', 'home', 'and', 'happy'), 1), (('home', 'and', 'happy', 'disposition'), 1), (('and', 'happy', 'disposition', ','), 1), (('happy', 'disposition', ',', 'seemed'), 1), (('disposition', ',', 'seemed', 'to'), 1), ((',', 'seemed', 'to', 'unite'), 1)]
Last 30 4-grams --
[((',', 'the', 'confidence', ','), 1), (('the', 'confidence', ',', 'the'), 1), (('confidence', ',', 'the', 'predictions'), 1), ((',', 'the', 'predictions', 'of'), 1), (('the', 'predictions', 'of', 'the'), 1), (('predictions', 'of', 'the', 'small'), 1), (('of', 'the', 'small', 'band'), 1), (('the', 'small', 'band', 'of'), 1), (('small', 'band', 'of', 'true'), 1), (('band', 'of', 'true', 'friends'), 1), (('of', 'true', 'friends', 'who'), 1), (('true', 'friends', 'who', 'witnessed'), 1), (('friends', 'who', 'witnessed', 'the'), 1), (('who', 'witnessed', 'the', 'ceremony'), 1), (('witnessed', 'the', 'ceremony', ','), 1), (('the', 'ceremony', ',', 'were'), 1), (('ceremony', ',', 'were', 'fully'), 1), ((',', 'were', 'fully', 'answered'), 1), (('were', 'fully', 'answered', 'in'), 1), (('fully', 'answered', 'in', 'the'), 1), (('answered', 'in', 'the', 'perfect'), 1), (('in', 'the', 'perfect', 'happiness'), 1), (('the', 'perfect', 'happiness', 'of'), 1), (('perfect', 'happiness', 'of', 'the'), 1), (('happiness', 'of', 'the', 'union'), 1), (('of', 'the', 'union', '.'), 1), (('the', 'union', '.', '</s>'), 1), (('union', '.', '</s>', '<s>'), 1), (('.', '</s>', '<s>', 'FINIS'), 1), (('</s>', '<s>', 'FINIS', '</s>'), 1)]
>>> 
