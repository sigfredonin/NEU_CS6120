(venv) (base) C:\Users\Alice\NLP\NEU_CS6120\project>python utils.py
====December 06, 2018 05:32:13 PM====
------------------------------- Hyper-parameters -------------------------------
USE_FULL_TRAIN: True, TRAIN_SIZE: 20000
Full training set size - sarcastic: 20000, non-sarcastic: 100000
Senti-scores - # most common n-grams: 20000, remove common n-grams: True
Senti-scores - min senses: 3, max senses: 12
Senti-scores - remove stopwords: False remove punctuation: False
Senti-scores - punctuation: , . : .. ; ...
--------------------------------------------------------------------------------
num sarcastic tweets: 25273
num non sarcastic tweets: 117825
Scoring sentiment in 120000 tweets ...
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
..................................................
[(0, 18585), (2, 8751), (1, 7430), (3, 6501), (-2, 6297), (-1, 5745), (4, 5672), (-3, 5275), (5, 4677), (-4, 4057), (6, 3534), (-5, 3058), (7, 2815), (8, 2336), (-6, 2230), (11, 2085), (9, 1966), (10, 1874), (-7, 1671), (-8, 1591)]
Tweets with scored words: 110367; total words scored: 373437
Tweets with exceptions: 118152; total exceptions: 6664437
Total word/tags with scores: 9243
Scoring sentiment in 23098 tweets ...
..................................................
..................................................
..................................................
..................................................
..............................[(0, 3412), (2, 1735), (1, 1443), (-2, 1284), (3, 1184), (-1, 1128), (4, 1064), (-3, 990), (5, 905), (-4, 753), (6, 680), (-5, 590), (7, 558), (8, 452), (-6, 445), (11, 395), (9, 368), (10, 352), (-7, 335), (-8, 307)]
Tweets with scored words: 21341; total words scored: 73110
Tweets with exceptions: 22783; total exceptions: 1283085
Total word/tags with scores: 9739
Training features:
[[ 0  1  0  3  0  4 -8]
 [ 0  6  0  6  0  7 -3]]
Training labels:
[1 1 1 1 1 1 1 1 1 1]
Testing features:
[[0 0 0 3 0 0 1]
 [1 2 1 0 0 5 0]]
Testing labels:
[1 1 1 1 1 1 1 1 1 1]
====December 06, 2018 05:44:13 PM====
Ten-fold cross-validate ...
cross-validating svm...
--------------------------------- Trial 1 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 0 0 1 1 1 1 1 1 1] [0 0 0 0 1 0 0 0 0 0]
mean squared error: 0.2125
pearson coefficient: (0.39657992039082507, 0.0)
f-score: 0.5109321058688149
--------------------------------- Trial 2 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 1 0 1 1 1 0 0] [0 0 0 0 0 0 0 1 0 0]
mean squared error: 0.21866666666666668
pearson coefficient: (0.38260489885436305, 0.0)
f-score: 0.4975105323630793
--------------------------------- Trial 3 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [1 1 0 1 1 1 1 0 0 0] [0 0 0 0 1 1 0 0 0 1]
mean squared error: 0.21666666666666667
pearson coefficient: (0.3751583392692924, 0.0)
f-score: 0.490795142969056
--------------------------------- Trial 4 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [1 1 0 0 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
mean squared error: 0.21825
pearson coefficient: (0.38887415838080786, 0.0)
f-score: 0.49837195939475193
--------------------------------- Trial 5 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [1 1 1 1 1 1 1 1 0 0] [0 0 0 0 0 0 1 0 0 0]
mean squared error: 0.20316666666666666
pearson coefficient: (0.4101816602545228, 0.0)
f-score: 0.5179913009094504
--------------------------------- Trial 6 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [1 1 1 1 1 1 1 1 1 1] [1 0 0 1 0 0 0 1 0 0]
mean squared error: 0.21408333333333332
pearson coefficient: (0.38855592394880156, 0.0)
f-score: 0.5008742957062366
--------------------------------- Trial 7 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 1 1 1 1 1 1 1] [0 1 0 1 0 0 0 1 0 0]
mean squared error: 0.21525
pearson coefficient: (0.3842619175511323, 0.0)
f-score: 0.4940254652301665
--------------------------------- Trial 8 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [1 0 0 0 1 0 1 1 1 0] [0 0 1 0 1 0 1 0 1 1]
mean squared error: 0.2165
pearson coefficient: (0.3889754371167839, 0.0)
f-score: 0.5024894676369207
--------------------------------- Trial 9 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 0 1 1 0 1 0 1] [0 1 0 0 1 0 0 0 0 0]
mean squared error: 0.21766666666666667
pearson coefficient: (0.3808937413881435, 0.0)
f-score: 0.4945820433436532
-------------------------------- Trial 10 of 10---------------------------------
training svm with kernel='linear', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 1 0 1 1 1 1 1] [0 1 0 0 0 1 0 0 0 0]
mean squared error: 0.21941666666666668
pearson coefficient: (0.3833158293729858, 0.0)
f-score: 0.4949165547669288
=====================> Mean Squared Error over all trials <=====================
Mean Squared Error min:   0.2032
Mean Squared Error mean:  0.2152
Mean Squared Error max:   0.2194
================================================================================
====================> Pearson Coefficients over all trials <====================
Pearson Coefficients min:   0.3752
Pearson Coefficients mean:  0.3879
Pearson Coefficients max:   0.4102
================================================================================
==========================> F-Scores over all trials <==========================
F-Scores min:   0.4908
F-Scores mean:  0.5002
F-Scores max:   0.5180
================================================================================
====December 06, 2018 07:03:36 PM====

(venv) (base) C:\Users\Alice\NLP\NEU_CS6120\project>
