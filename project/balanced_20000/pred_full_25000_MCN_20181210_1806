====December 10, 2018 06:13:55 PM====
------------------------------- Hyper-parameters -------------------------------
USE_FULL_TRAIN: False, TRAIN_SIZE: 20000
Full training set size - sarcastic: 20000, non-sarcastic: 100000
Senti-scores - # most common n-grams: 25000, remove common n-grams: True
Senti-scores - min senses: 3, max senses: 12
Senti-scores - remove stopwords: False remove punctuation: False
Senti-scores - punctuation: ; .. , . ... :
--------------------------------------------------------------------------------
num sarcastic tweets: 25273
num non sarcastic tweets: 117825
Scoring sentiment in 20000 tweets ...
..................................................
..................................................
..................................................
..................................................
[(0, 2892), (2, 1418), (1, 1205), (3, 1015), (-2, 959), (4, 903), (-1, 888), (5, 829), (-3, 819), (-4, 621), (6, 557), (7, 490), (-5, 490), (8, 424), (11, 386), (9, 378), (10, 339), (-6, 337), (13, 309), (12, 274)]
Tweets with scored words: 18525; total words scored: 63595
Tweets with exceptions: 19729; total exceptions: 1138583
Total word/tags with scores: 5060
Scoring sentiment in 23098 tweets ...
..................................................
..................................................
..................................................
..................................................
..............................[(0, 3412), (2, 1735), (1, 1443), (-2, 1284), (3, 1184), (-1, 1128), (4, 1064), (-3, 990), (5, 905), (-4, 753), (6, 680), (-5, 590), (7, 558), (8, 452), (-6, 445), (11, 395), (9, 368), (10, 352), (-7, 335), (-8, 307)]
Tweets with scored words: 21341; total words scored: 73110
Tweets with exceptions: 22800; total exceptions: 1291988
Total word/tags with scores: 6833
Training features:
[[ 0  2  0  0  0  4 -8]
 [ 1 10  1  0  0  7 -3]]
Training labels:
[1 1 1 1 1 1 1 1 1 1]
Testing features:
[[0 0 0 0 0 0 1]
 [0 1 0 0 0 5 0]]
Testing labels:
[1 1 1 1 1 1 1 1 1 1]
====December 10, 2018 06:17:33 PM====
++++++++++++++++++++++++++++ Multilayer Perceptron +++++++++++++++++++++++++++++
Train and predict ...
====December 10, 2018 06:17:46 PM====
--- Model ---
Input    : 1 x 7
Layer h1 : 7 x 60 relu
Layer h2 : 60 x 10 relu
Output   : 10 x 1 SIGMOID
----------
====December 10, 2018 06:17:46 PM====
Epoch 1/10

   32/20000 [..............................] - ETA: 3:04 - loss: 1.1576 - mean_squared_error: 0.3714 - acc: 0.4062
 1760/20000 [=>............................] - ETA: 3s - loss: 0.6767 - mean_squared_error: 0.2361 - acc: 0.6176  
 3872/20000 [====>.........................] - ETA: 1s - loss: 0.5270 - mean_squared_error: 0.1743 - acc: 0.7665
 6272/20000 [========>.....................] - ETA: 1s - loss: 0.4058 - mean_squared_error: 0.1293 - acc: 0.8377
 8736/20000 [============>.................] - ETA: 0s - loss: 0.3330 - mean_squared_error: 0.1043 - acc: 0.8711
11168/20000 [===============>..............] - ETA: 0s - loss: 0.2871 - mean_squared_error: 0.0891 - acc: 0.8904
13632/20000 [===================>..........] - ETA: 0s - loss: 0.2561 - mean_squared_error: 0.0792 - acc: 0.9021
16096/20000 [=======================>......] - ETA: 0s - loss: 0.2333 - mean_squared_error: 0.0720 - acc: 0.9102
18144/20000 [==========================>...] - ETA: 0s - loss: 0.2188 - mean_squared_error: 0.0676 - acc: 0.9153
20000/20000 [==============================] - 1s 40us/step - loss: 0.2077 - mean_squared_error: 0.0641 - acc: 0.9194
Epoch 2/10

   32/20000 [..............................] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0284 - acc: 0.9688
 2464/20000 [==>...........................] - ETA: 0s - loss: 0.0961 - mean_squared_error: 0.0292 - acc: 0.9623
 4512/20000 [=====>........................] - ETA: 0s - loss: 0.0974 - mean_squared_error: 0.0295 - acc: 0.9612
 7040/20000 [=========>....................] - ETA: 0s - loss: 0.0976 - mean_squared_error: 0.0304 - acc: 0.9589
 9568/20000 [=============>................] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.0302 - acc: 0.9597
12160/20000 [=================>............] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0314 - acc: 0.9568
14176/20000 [====================>.........] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0312 - acc: 0.9569
16768/20000 [========================>.....] - ETA: 0s - loss: 0.0986 - mean_squared_error: 0.0312 - acc: 0.9572
18784/20000 [===========================>..] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.0313 - acc: 0.9571
20000/20000 [==============================] - 0s 25us/step - loss: 0.0995 - mean_squared_error: 0.0316 - acc: 0.9567
Epoch 3/10

   32/20000 [..............................] - ETA: 0s - loss: 0.0939 - mean_squared_error: 0.0325 - acc: 0.9375
 1984/20000 [=>............................] - ETA: 0s - loss: 0.0952 - mean_squared_error: 0.0307 - acc: 0.9546
 4192/20000 [=====>........................] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.0314 - acc: 0.9561
 6688/20000 [=========>....................] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0317 - acc: 0.9550
 8736/20000 [============>.................] - ETA: 0s - loss: 0.0964 - mean_squared_error: 0.0310 - acc: 0.9562
11296/20000 [===============>..............] - ETA: 0s - loss: 0.0958 - mean_squared_error: 0.0308 - acc: 0.9567
13792/20000 [===================>..........] - ETA: 0s - loss: 0.0969 - mean_squared_error: 0.0312 - acc: 0.9563
15872/20000 [======================>.......] - ETA: 0s - loss: 0.0968 - mean_squared_error: 0.0311 - acc: 0.9567
18496/20000 [==========================>...] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.0309 - acc: 0.9570
20000/20000 [==============================] - 0s 25us/step - loss: 0.0958 - mean_squared_error: 0.0309 - acc: 0.9569
Epoch 4/10

   32/20000 [..............................] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.0327 - acc: 0.9375
 2240/20000 [==>...........................] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0277 - acc: 0.9634
 4800/20000 [======>.......................] - ETA: 0s - loss: 0.0920 - mean_squared_error: 0.0301 - acc: 0.9592
 7264/20000 [=========>....................] - ETA: 0s - loss: 0.0905 - mean_squared_error: 0.0297 - acc: 0.9590
 9728/20000 [=============>................] - ETA: 0s - loss: 0.0926 - mean_squared_error: 0.0303 - acc: 0.9580
11744/20000 [================>.............] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.0297 - acc: 0.9592
13888/20000 [===================>..........] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0296 - acc: 0.9593
16416/20000 [=======================>......] - ETA: 0s - loss: 0.0943 - mean_squared_error: 0.0309 - acc: 0.9570
18912/20000 [===========================>..] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.0308 - acc: 0.9571
20000/20000 [==============================] - 1s 25us/step - loss: 0.0942 - mean_squared_error: 0.0309 - acc: 0.9568
Epoch 5/10

   32/20000 [..............................] - ETA: 1s - loss: 0.0814 - mean_squared_error: 0.0322 - acc: 0.9375
 2016/20000 [==>...........................] - ETA: 0s - loss: 0.0919 - mean_squared_error: 0.0304 - acc: 0.9583
 4096/20000 [=====>........................] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.0302 - acc: 0.9575
 6560/20000 [========>.....................] - ETA: 0s - loss: 0.0916 - mean_squared_error: 0.0301 - acc: 0.9588
 9088/20000 [============>.................] - ETA: 0s - loss: 0.0945 - mean_squared_error: 0.0310 - acc: 0.9573
11584/20000 [================>.............] - ETA: 0s - loss: 0.0950 - mean_squared_error: 0.0313 - acc: 0.9564
14112/20000 [====================>.........] - ETA: 0s - loss: 0.0945 - mean_squared_error: 0.0312 - acc: 0.9565
16640/20000 [=======================>......] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0316 - acc: 0.9559
19168/20000 [===========================>..] - ETA: 0s - loss: 0.0949 - mean_squared_error: 0.0314 - acc: 0.9561
20000/20000 [==============================] - 0s 25us/step - loss: 0.0945 - mean_squared_error: 0.0312 - acc: 0.9566
Epoch 6/10

   32/20000 [..............................] - ETA: 0s - loss: 0.1923 - mean_squared_error: 0.0684 - acc: 0.8750
 2304/20000 [==>...........................] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.0283 - acc: 0.9618
 4544/20000 [=====>........................] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.0266 - acc: 0.9635
 7072/20000 [=========>....................] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0283 - acc: 0.9610
 9600/20000 [=============>................] - ETA: 0s - loss: 0.0875 - mean_squared_error: 0.0291 - acc: 0.9596
12160/20000 [=================>............] - ETA: 0s - loss: 0.0907 - mean_squared_error: 0.0299 - acc: 0.9583
14208/20000 [====================>.........] - ETA: 0s - loss: 0.0894 - mean_squared_error: 0.0295 - acc: 0.9584
16768/20000 [========================>.....] - ETA: 0s - loss: 0.0907 - mean_squared_error: 0.0300 - acc: 0.9580
18752/20000 [===========================>..] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0303 - acc: 0.9578
20000/20000 [==============================] - 1s 25us/step - loss: 0.0913 - mean_squared_error: 0.0303 - acc: 0.9578
Epoch 7/10

   32/20000 [..............................] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.0282 - acc: 0.9688
 1984/20000 [=>............................] - ETA: 0s - loss: 0.0922 - mean_squared_error: 0.0308 - acc: 0.9567
 4224/20000 [=====>........................] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0336 - acc: 0.9531
 6720/20000 [=========>....................] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0322 - acc: 0.9554
 9248/20000 [============>.................] - ETA: 0s - loss: 0.0947 - mean_squared_error: 0.0311 - acc: 0.9572
11744/20000 [================>.............] - ETA: 0s - loss: 0.0940 - mean_squared_error: 0.0310 - acc: 0.9565
14304/20000 [====================>.........] - ETA: 0s - loss: 0.0925 - mean_squared_error: 0.0304 - acc: 0.9578
16512/20000 [=======================>......] - ETA: 0s - loss: 0.0912 - mean_squared_error: 0.0300 - acc: 0.9580
19008/20000 [===========================>..] - ETA: 0s - loss: 0.0910 - mean_squared_error: 0.0300 - acc: 0.9581
20000/20000 [==============================] - 0s 25us/step - loss: 0.0912 - mean_squared_error: 0.0301 - acc: 0.9578
Epoch 8/10

   32/20000 [..............................] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0035 - acc: 1.0000
 2144/20000 [==>...........................] - ETA: 0s - loss: 0.0874 - mean_squared_error: 0.0290 - acc: 0.9571
 4096/20000 [=====>........................] - ETA: 0s - loss: 0.0929 - mean_squared_error: 0.0308 - acc: 0.9558
 6528/20000 [========>.....................] - ETA: 0s - loss: 0.0901 - mean_squared_error: 0.0298 - acc: 0.9580
 9056/20000 [============>.................] - ETA: 0s - loss: 0.0897 - mean_squared_error: 0.0298 - acc: 0.9575
11072/20000 [===============>..............] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.0297 - acc: 0.9582
13056/20000 [==================>...........] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.0294 - acc: 0.9593
15616/20000 [======================>.......] - ETA: 0s - loss: 0.0903 - mean_squared_error: 0.0297 - acc: 0.9589
17568/20000 [=========================>....] - ETA: 0s - loss: 0.0899 - mean_squared_error: 0.0297 - acc: 0.9590
19776/20000 [============================>.] - ETA: 0s - loss: 0.0899 - mean_squared_error: 0.0297 - acc: 0.9589
20000/20000 [==============================] - 1s 26us/step - loss: 0.0905 - mean_squared_error: 0.0299 - acc: 0.9586
Epoch 9/10

   32/20000 [..............................] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0381 - acc: 0.9375
 2048/20000 [==>...........................] - ETA: 0s - loss: 0.0969 - mean_squared_error: 0.0324 - acc: 0.9546
 4448/20000 [=====>........................] - ETA: 0s - loss: 0.0969 - mean_squared_error: 0.0324 - acc: 0.9553
 6432/20000 [========>.....................] - ETA: 0s - loss: 0.0965 - mean_squared_error: 0.0322 - acc: 0.9546
 8768/20000 [============>.................] - ETA: 0s - loss: 0.0930 - mean_squared_error: 0.0309 - acc: 0.9571
11264/20000 [===============>..............] - ETA: 0s - loss: 0.0926 - mean_squared_error: 0.0306 - acc: 0.9577
13760/20000 [===================>..........] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0311 - acc: 0.9568
16192/20000 [=======================>......] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0304 - acc: 0.9581
18656/20000 [==========================>...] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0303 - acc: 0.9580
20000/20000 [==============================] - 1s 25us/step - loss: 0.0904 - mean_squared_error: 0.0299 - acc: 0.9587
Epoch 10/10

   32/20000 [..............................] - ETA: 0s - loss: 0.2699 - mean_squared_error: 0.0933 - acc: 0.8438
 1952/20000 [=>............................] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0286 - acc: 0.9595
 4000/20000 [=====>........................] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.0286 - acc: 0.9595
 6400/20000 [========>.....................] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.0295 - acc: 0.9587
 8896/20000 [============>.................] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.0298 - acc: 0.9580
11456/20000 [================>.............] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.0296 - acc: 0.9581
13472/20000 [===================>..........] - ETA: 0s - loss: 0.0904 - mean_squared_error: 0.0302 - acc: 0.9576
16000/20000 [=======================>......] - ETA: 0s - loss: 0.0896 - mean_squared_error: 0.0297 - acc: 0.9586
18048/20000 [==========================>...] - ETA: 0s - loss: 0.0911 - mean_squared_error: 0.0303 - acc: 0.9581
20000/20000 [==============================] - 1s 25us/step - loss: 0.0907 - mean_squared_error: 0.0302 - acc: 0.9583
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 0 0 0 1 1 1 1] [0 0 1 0 0 1 1 0 0 1]
... MSE: 0.340982 PEARSON: (0.2650490649337206, 0.0) F-SCORE: 0.464655
+++++++++++++++++++++++++++++++++ Max Entropy ++++++++++++++++++++++++++++++++++
Train and predict ...
training max_ent with penalty=l2, solver=sag, C=1.0, and class_weight=balanced
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 0 0 0 1 1 1 1] [0 0 1 0 0 1 1 0 0 1]
mean squared error: 0.34375270586197937
pearson coefficient: (0.2578068236807347, 0.0)
f-score: 0.4599374234797986
... MSE: 0.343753 PEARSON: (0.2578068236807347, 0.0) F-SCORE: 0.459937
++++++++++++++++++++++++++++ Support Vector Machine ++++++++++++++++++++++++++++
Train and predict ...
training svm with kernel='rbf', C=1.0, gamma='scale', class_weight='balanced'
test [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]
pred [0 1 1 0 1 0 1 1 1 1] [0 0 1 1 0 1 1 0 0 1]
mean squared error: 0.39899558403324964
pearson coefficient: (0.230580368699184, 2.293236595193864e-276)
f-score: 0.44622040620117776
... MSE: 0.398996 PEARSON: (0.230580368699184, 2.293236595193864e-276) F-SCORE: 0.446220
====December 10, 2018 06:18:01 PM====
